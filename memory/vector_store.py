from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from langchain_openai import OpenAIEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
from config.settings import settings
from typing import List, Dict
import uuid

class VectorStore:
    def __init__(self):
        self.client = QdrantClient(
            host=settings.qdrant_host,
            port=settings.qdrant_port
        )
        
        # æ ¹æ®é…ç½®é€‰æ‹©Embeddingæ¨¡å‹
        self.embeddings = None
        self.embedding_dim = 1024  # é»˜è®¤ç»´åº¦
        
        if settings.embedding_model == "openai":
            # OpenAI Embeddingsï¼ˆéœ€è¦APIå¯†é’¥ï¼‰
            if settings.openai_api_key:
                self.embeddings = OpenAIEmbeddings(
                    openai_api_key=settings.openai_api_key,
                    model="text-embedding-3-small"
                )
                self.embedding_dim = 1536
                print("âœ… ä½¿ç”¨OpenAI Embeddings")
            else:
                print("âš ï¸  æœªé…ç½®OpenAI APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°BGE-M3æ¨¡å‹")
                settings.embedding_model = "bge-m3"  # è‡ªåŠ¨åˆ‡æ¢
        
        if settings.embedding_model == "bge-m3":
            # BGE-M3æœ¬åœ°æ¨¡å‹ï¼ˆå¼€æºï¼Œæ— éœ€APIï¼‰
            print("ğŸ“¦ åŠ è½½BGE-M3æœ¬åœ°Embeddingæ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æ¨¡å‹ï¼Œçº¦2GBï¼‰...")
            self.embeddings = HuggingFaceEmbeddings(
                model_name="BAAI/bge-m3",
                model_kwargs={'device': 'cpu'},  # ä½¿ç”¨CPUï¼Œå¦‚æœæœ‰GPUå¯æ”¹ä¸º'cuda'
                encode_kwargs={'normalize_embeddings': True}
            )
            self.embedding_dim = 1024
            print("âœ… BGE-M3æ¨¡å‹åŠ è½½å®Œæˆï¼æ”¯æŒä¸­æ–‡ã€è‹±è¯­ã€è·å…°è¯­ç­‰100+è¯­è¨€")
        
        # ä¸ºæ¯ç§è¯­è¨€åˆ›å»ºé›†åˆ
        for lang in settings.supported_languages:
            self._ensure_collection(f"conversations_{lang}")
    
    def _ensure_collection(self, collection_name: str):
        """ç¡®ä¿é›†åˆå­˜åœ¨"""
        try:
            collections = self.client.get_collections().collections
            collection_names = [c.name for c in collections]
            
            if collection_name not in collection_names:
                self.client.create_collection(
                    collection_name=collection_name,
                    vectors_config=VectorParams(
                        size=self.embedding_dim,
                        distance=Distance.COSINE
                    )
                )
                print(f"âœ… åˆ›å»ºå‘é‡é›†åˆ: {collection_name} (ç»´åº¦: {self.embedding_dim})")
        except Exception as e:
            print(f"âŒ åˆ›å»ºé›†åˆ {collection_name} å¤±è´¥: {e}")
    
    async def add_conversation(
        self,
        user_id: str,
        language: str,
        user_message: str,
        bot_response: str,
        conversation_id: str
    ):
        """æ·»åŠ å¯¹è¯åˆ°å‘é‡æ•°æ®åº“"""
        # å¦‚æœæ²¡æœ‰é…ç½®embeddingsï¼Œè·³è¿‡å‘é‡å­˜å‚¨
        if not self.embeddings:
            print("âš ï¸  æœªé…ç½®Embeddingæ¨¡å‹ï¼Œè·³è¿‡å‘é‡å­˜å‚¨")
            return
            
        try:
            # åˆå¹¶å¯¹è¯å†…å®¹
            text = f"ç”¨æˆ·: {user_message}\nåŠ©æ‰‹: {bot_response}"
            
            # ç”Ÿæˆembedding
            embedding = await self.embeddings.aembed_query(text)
            
            # å­˜å‚¨åˆ°Qdrant
            self.client.upsert(
                collection_name=f"conversations_{language}",
                points=[
                    PointStruct(
                        id=str(uuid.uuid4()),
                        vector=embedding,
                        payload={
                            "user_id": user_id,
                            "conversation_id": conversation_id,
                            "user_message": user_message,
                            "bot_response": bot_response,
                            "text": text
                        }
                    )
                ]
            )
            print(f"âœ… å¯¹è¯å·²ä¿å­˜åˆ°å‘é‡æ•°æ®åº“ (æ¨¡å‹: {settings.embedding_model})")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¯¹è¯åˆ°å‘é‡æ•°æ®åº“å¤±è´¥: {e}")
    
    async def search_similar_conversations(
        self,
        user_id: str,
        language: str,
        query: str,
        limit: int = 3
    ) -> List[Dict]:
        """æœç´¢ç›¸ä¼¼å¯¹è¯"""
        # å¦‚æœæ²¡æœ‰é…ç½®embeddingsï¼Œè¿”å›ç©ºåˆ—è¡¨
        if not self.embeddings:
            return []
            
        try:
            # ç”Ÿæˆquery embedding
            query_embedding = await self.embeddings.aembed_query(query)
            
            # æœç´¢
            results = self.client.search(
                collection_name=f"conversations_{language}",
                query_vector=query_embedding,
                query_filter={
                    "must": [
                        {"key": "user_id", "match": {"value": user_id}}
                    ]
                },
                limit=limit
            )
            
            similar_convs = [
                {
                    "text": hit.payload["text"],
                    "score": hit.score
                }
                for hit in results
            ]
            
            if similar_convs:
                print(f"ğŸ” æ‰¾åˆ° {len(similar_convs)} æ¡ç›¸ä¼¼å¯¹è¯ (æ¨¡å‹: {settings.embedding_model})")
            
            return similar_convs
        except Exception as e:
            print(f"âŒ æœç´¢ç›¸ä¼¼å¯¹è¯å¤±è´¥: {e}")
            return []
